import fs from 'fs/promises';
import path from 'path';
import matter from 'gray-matter';

const articlesContentDirectory = path.join(process.cwd(), 'packages/frontend/content/articles');
const outputSqlFile = path.join(process.cwd(), 'migration.sql');

// Helper to create a URL-friendly slug
const slugify = (str) => {
  if (!str) return '';
  return str.toString().toLowerCase().trim()
    .replace(/\s+/g, '-')           // Replace spaces with -
    .replace(/[&.+~,()"'!:@]/g, '') // Remove special characters
    .replace(/--+/g, '-');          // Replace multiple - with single -
};

// Helper to escape single quotes for SQL
const escapeSql = (str) => {
    if (typeof str !== 'string') return str;
    return str.replace(/'/g, "''");
};

async function collectArticleFilePaths(dir) {
  let files = [];
  try {
    const entries = await fs.readdir(dir, { withFileTypes: true });
    for (const entry of entries) {
      const fullPath = path.join(dir, entry.name);
      if (entry.isDirectory()) {
        files = files.concat(await collectArticleFilePaths(fullPath));
      } else if (entry.isFile() && entry.name.endsWith('.md')) {
        files.push(fullPath);
      }
    }
  } catch (error) {
    console.error(`Error reading articles directory (${dir}):`, error);
  }
  return files;
}

async function generateMigration() {
  console.log('Starting article migration...');

  const allCategories = new Map();
  const allTags = new Map();
  const allArticles = [];

  const filePaths = await collectArticleFilePaths(articlesContentDirectory);
  console.log(`Found ${filePaths.length} article files.`);

  for (const filePath of filePaths) {
    const fileContents = await fs.readFile(filePath, 'utf8');
    const { data, content } = matter(fileContents);
    const slug = path.basename(filePath, '.md');

    // Collect categories
    if (data.category) {
      const categorySlug = slugify(data.category);
      if (!allCategories.has(categorySlug)) {
        allCategories.set(categorySlug, { name: data.category, slug: categorySlug });
      }
    }

    // Collect tags
    const articleTags = [];
    if (data.tags) {
        const tags = Array.isArray(data.tags) ? data.tags : String(data.tags).split(',').map(t => t.trim());
        for (const tagName of tags) {
            if (!tagName) continue;
            const tagSlug = slugify(tagName);
            if (!allTags.has(tagSlug)) {
                allTags.set(tagSlug, { name: tagName, slug: tagSlug });
            }
            articleTags.push(tagSlug);
        }
    }

    allArticles.push({
      slug,
      title: data.title || 'Untitled',
      content,
      excerpt: data.excerpt || '',
      thumbnail: data.thumbnail || null,
      published_at: data.publishedAt ? new Date(data.publishedAt).getTime() / 1000 : null,
      is_premium: ['true', '1', 'yes', 'on'].includes(String(data.isPremium).toLowerCase()),
      author: data.author || 'Unknown',
      category_slug: data.category ? slugify(data.category) : null,
      tags: articleTags,
    });
  }

  let sql = '-- Generated by migration script\n\n';
  sql += 'BEGIN TRANSACTION;\n\n';

  // Generate Categories SQL
  console.log(`Found ${allCategories.size} unique categories.`);
  sql += '-- Insert Categories\n';
  for (const [slug, category] of allCategories) {
    sql += `INSERT INTO categories (name, slug) VALUES ('${escapeSql(category.name)}', '${escapeSql(slug)}') ON CONFLICT(slug) DO NOTHING;\n`;
  }
  sql += '\n';

  // Generate Tags SQL
  console.log(`Found ${allTags.size} unique tags.`);
  sql += '-- Insert Tags\n';
  for (const [slug, tag] of allTags) {
    sql += `INSERT INTO tags (name, slug) VALUES ('${escapeSql(tag.name)}', '${escapeSql(slug)}') ON CONFLICT(slug) DO NOTHING;\n`;
  }
  sql += '\n';

  // Generate Articles and Article-Tags SQL
  console.log(`Generating SQL for ${allArticles.length} articles.`);
  sql += '-- Insert Articles and Associations\n';
  for (const article of allArticles) {
    const publishedAtValue = article.published_at ? parseInt(article.published_at, 10) : 'NULL';
    const thumbnailValue = article.thumbnail ? `'${escapeSql(article.thumbnail)}'` : 'NULL';
    const categoryIdSubquery = article.category_slug ? `(SELECT id FROM categories WHERE slug = '${escapeSql(article.category_slug)}')` : 'NULL';

    sql += `INSERT INTO articles (slug, title, content, excerpt, thumbnail, published_at, is_premium, author, category_id, updated_at) VALUES (
      '${escapeSql(article.slug)}',
      '${escapeSql(article.title)}',
      '${escapeSql(article.content)}',
      '${escapeSql(article.excerpt)}',
      ${thumbnailValue},
      ${publishedAtValue},
      ${article.is_premium ? 1 : 0},
      '${escapeSql(article.author)}',
      ${categoryIdSubquery},
      (strftime('%s', 'now'))
    ) ON CONFLICT(slug) DO UPDATE SET
      title = excluded.title,
      content = excluded.content,
      excerpt = excluded.excerpt,
      thumbnail = excluded.thumbnail,
      published_at = excluded.published_at,
      is_premium = excluded.is_premium,
      author = excluded.author,
      category_id = excluded.category_id,
      updated_at = (strftime('%s', 'now'));\n`;

    // Clear existing tags for this article on update
    sql += `DELETE FROM article_tags WHERE article_id = (SELECT id FROM articles WHERE slug = '${escapeSql(article.slug)}');\n`;

    // Insert new tags
    for (const tagSlug of article.tags) {
        sql += `INSERT INTO article_tags (article_id, tag_id) VALUES (
          (SELECT id FROM articles WHERE slug = '${escapeSql(article.slug)}') ,
          (SELECT id FROM tags WHERE slug = '${escapeSql(tagSlug)}')
        );\n`;
    }
    sql += '\n';
  }

  sql += 'COMMIT;\n';

  await fs.writeFile(outputSqlFile, sql);
  console.log(`Successfully generated migration SQL file at ${outputSqlFile}`);
  console.log(`\nNext step: Run the following command to apply the migration:\n`);
  console.log(`npx wrangler d1 execute takayama-db --local --file=${outputSqlFile}\n`);
}

generateMigration().catch(console.error);
